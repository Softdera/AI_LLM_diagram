
This folder contains a short explanation and a simple diagram explaining how
Large Language Models process text using tokenization, attention, and
transformer blocks.
